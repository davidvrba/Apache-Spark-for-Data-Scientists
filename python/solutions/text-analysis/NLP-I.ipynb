{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92899fb1",
   "metadata": {},
   "source": [
    "In this notebook use the spark-nlp library to compute the NER of the title/body columns from the questions dataset.\n",
    "\n",
    "* spark-nlp [docs](https://nlp.johnsnowlabs.com/docs/en/quickstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8cabba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import size, col, sum, expr, explode, desc, length\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "from sparknlp.base import DocumentAssembler\n",
    "from sparknlp.annotator import SentenceDetector, Tokenizer, BertEmbeddings, NerDLModel, NerConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2e3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('NLP I')\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:4.3.2\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c591624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "\n",
    "project_path = ('/').join(base_path.split('/')[0:-2]) \n",
    "\n",
    "data_input_path = os.path.join(project_path, 'data/questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77953507",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF = (\n",
    "    spark\n",
    "    .read\n",
    "    .option('path', data_input_path)\n",
    "    .load()\n",
    "    .withColumnRenamed('title', 'Text')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be99d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentAssembler = (\n",
    "    DocumentAssembler()\n",
    "    .setInputCol('Text')\n",
    "    .setOutputCol('document')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0a9cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceDetector = (\n",
    "    SentenceDetector()\n",
    "    .setInputCols('document')\n",
    "    .setOutputCol('sentence')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaa27cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline().setStages([documentAssembler, sentenceDetector]).fit(dataDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a5526",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "  model.transform(dataDF)\n",
    "  .withColumn('sentences', size('sentence'))\n",
    "  .agg(sum('sentences'))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6ba02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = (\n",
    "    Tokenizer()\n",
    "    .setInputCols(['document'])\n",
    "    .setOutputCol('token')\n",
    ")\n",
    "\n",
    "model = Pipeline().setStages([documentAssembler, tokenizer]).fit(dataDF)\n",
    "\n",
    "model.transform(dataDF).select('token').show(truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761ad284",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = (\n",
    "    BertEmbeddings\n",
    "    .pretrained('bert_base_cased', 'en')\n",
    "    .setInputCols(['token', 'document'])\n",
    "    .setOutputCol('embeddings')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9482c57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline().setStages([documentAssembler, tokenizer, embeddings]).fit(dataDF)\n",
    "\n",
    "# model.transform(dataDF).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b334c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ner_converter = (\n",
    "    NerConverter()\n",
    "    .setInputCols(['document', 'token', 'ner'])\n",
    "    .setOutputCol('entities')\n",
    ")\n",
    "\n",
    "model = Pipeline().setStages([documentAssembler, tokenizer, embeddings, ner, ner_converter]).fit(dataDF)\n",
    "\n",
    "result = model.transform(df.filter(length(col('Text')) < 100))\n",
    "\n",
    "\n",
    "result.select('Text', 'entities').show()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
