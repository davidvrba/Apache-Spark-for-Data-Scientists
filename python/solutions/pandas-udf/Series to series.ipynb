{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43027e1e",
   "metadata": {},
   "source": [
    "# Statistical modeling\n",
    "\n",
    "In this notebook we will see how user defined functions can be used for statistical modeling using [scipy](http://scipy.github.io/devdocs/reference/index.html) package. We will also see how to implement Pandas UDF which has better performace than vanilla UDF because it can laverage [Apache Arrow](https://arrow.apache.org/) under the hood for exchanging the data and vectorized execution that is supported by the scipy package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde0442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, lit, count, year, pandas_udf, avg\n",
    "\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "import os\n",
    "\n",
    "from scipy.stats import poisson\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2b4b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('UDFs I')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c6a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "\n",
    "project_path = ('/').join(base_path.split('/')[0:-3]) \n",
    "\n",
    "answers_input_path = os.path.join(project_path, 'data/answers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c472de",
   "metadata": {},
   "source": [
    "## Task\n",
    "For each user compute probability that the user is going to answer 5 questions in the next year. Use simple model based on poisson distribution.\n",
    "\n",
    "* Create a DataFrame with two cols: user_id, answers, where the second is the average number of questions the user answered per year.\n",
    "* Implement UDF that will use poisson distribution from scipy package to compute the probability that if the user answered n questions per year, he will answer 5 questions in the next year\n",
    "* Implement the UDF again, but this time as Pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c0785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will need answers dataset:\n",
    "\n",
    "answersDF = (\n",
    "    spark\n",
    "    .read\n",
    "    .option('path', answers_input_path)\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc46ed0",
   "metadata": {},
   "source": [
    "## Create input DataFrame\n",
    "* filter for rows where user_id is not null\n",
    "* compute average number of answers per user per year\n",
    "* group by user and year\n",
    "* use count to see how many questions each user answered in each year\n",
    "* group by again but now only per user\n",
    "* compute the average per year for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6400d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = (\n",
    "    answersDF\n",
    "    .filter(col('user_id').isNotNull())\n",
    "    .withColumn('creation_year', year('creation_date'))\n",
    "    .groupBy(\n",
    "        'creation_year', 'user_id',\n",
    "    )\n",
    "    .agg(\n",
    "        count('*').alias('answers')\n",
    "    )\n",
    "    .groupBy('user_id')\n",
    "    .agg(\n",
    "        avg('answers').alias('answers')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7324db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771a3d3",
   "metadata": {},
   "source": [
    "## Define a python function\n",
    "### Hint:\n",
    "\n",
    "* it should take as argument year average and return the probability that `k` questions will be answered in next year\n",
    "* use [pmf](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.poisson.html#scipy.stats.poisson) function of the poisson in scipy\n",
    "* define `k` to be a constant equal 5\n",
    "* test if the function works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af59d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "k = 5\n",
    "\n",
    "def get_probability(year_average):\n",
    "    return poisson.pmf(k, year_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d623fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_probability(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9efc0a0",
   "metadata": {},
   "source": [
    "## Define the UDF:\n",
    "### Hint:\n",
    "\n",
    "* once you have the python function, make the UDF from it. See udf in [docs](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.udf.html#pyspark.sql.functions.udf)\n",
    "* the return type will be float, since we will compute probability\n",
    "* make sure to use the `float()` function for the return value to cast it to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b6a98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf('float')\n",
    "def get_probability(year_average):\n",
    "    return float(poisson.pmf(k, year_average))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89ec468",
   "metadata": {},
   "source": [
    "## Apply the udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e152db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    input_df\n",
    "    .withColumn('probability', get_probability(col('answers')))\n",
    ").show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377dbc06",
   "metadata": {},
   "source": [
    "## Try it with Pandas\n",
    "* create local Pandas dataframe with input data\n",
    "* pass a local Pandas series to poisson to see what it returns\n",
    "* define a function that will take pandas series as input argument and will return also pandas series\n",
    "\n",
    "### Hint:\n",
    "\n",
    "* create a pandas series from pandas dataframe as `local_data['answers']`, where local_data is pd_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c843e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data = input_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1386b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It returns numpy array\n",
    "\n",
    "poisson.pmf(k, local_data['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b179b2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can easily create a pandas series from it:\n",
    "\n",
    "pd.Series(poisson.pmf(k, local_data['answers']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddf8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability_pd(year_average):\n",
    "    return pd.Series(poisson.pmf(k, year_average))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38f7914",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_probability_pd(local_data['answers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4356586f",
   "metadata": {},
   "source": [
    "### Hint\n",
    "\n",
    "* Once you have the function make a pandas udf from it\n",
    "* See [pandas_udf](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.pandas_udf.html#pyspark.sql.functions.pandas_udf) in the docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd191be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pandas udf \n",
    "\n",
    "@pandas_udf('float')\n",
    "def get_probability_pd(year_average):\n",
    "    return pd.Series(poisson.pmf(k, year_average))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05922850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the UDF:\n",
    "\n",
    "(\n",
    "    input_df\n",
    "    .withColumn('probability', get_probability_pd(col('answers')))\n",
    ").show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be3ded3",
   "metadata": {},
   "source": [
    "## Compare the performace for both UDFs\n",
    "### Hint\n",
    "\n",
    "* run the query with the noop format\n",
    "* check the execution time in SparkUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ea4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution of vanilla UDF:\n",
    "\n",
    "(\n",
    "    input_df\n",
    "    .withColumn('probability', get_probability(col('answers')))\n",
    "    .write\n",
    "    .mode('overwrite')\n",
    "    .format('noop')\n",
    "    .save()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c8dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution of Pandas UDF:\n",
    "\n",
    "(\n",
    "    input_df\n",
    "    .withColumn('probability', get_probability_pd(col('answers')))\n",
    "    .write\n",
    "    .mode('overwrite')\n",
    "    .format('noop')\n",
    "    .save()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
