{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e720ae12",
   "metadata": {},
   "source": [
    "# Image processing\n",
    "\n",
    "In this notebook we will implement a udf that will load a Keras model that was trained to do a binary classification of images. It will classifiy the images into two classes: dog and cat.\n",
    "\n",
    "We will implement the UDF in three different ways to see the difference in execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a565a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, pandas_udf\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import io\n",
    "import os\n",
    "from typing import Iterator\n",
    "\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "keras = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca91cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('images')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc0e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accb7d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These constants are important for the image preprocessing because this is what the model expects\n",
    "IMG_SIZE = 160\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "\n",
    "base_path = os.getcwd()\n",
    "\n",
    "project_path = ('/').join(base_path.split('/')[0:-3]) \n",
    "\n",
    "images_input_path = os.path.join(project_path, 'data/cat-dog-images')\n",
    "\n",
    "model_path = os.path.join(project_path, 'models/keras-model-1/model.json')\n",
    "weights_path = os.path.join(project_path, 'models/keras-model-1/weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28f8fbd",
   "metadata": {},
   "source": [
    "### Read the images into a dataframe using the binaryFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbb601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "images = spark.read.format('binaryFile').load(images_input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef21f34c",
   "metadata": {},
   "source": [
    "The Keras model is represented with the model.json file and weights.h5. Load the model from these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78477e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "json_file = open(model_path, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "loaded_model = keras.models.model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0df1b8f",
   "metadata": {},
   "source": [
    "### Broadcast the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6c44ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = loaded_model.get_weights()\n",
    "\n",
    "model_json_bc = spark.sparkContext.broadcast(loaded_model_json)\n",
    "weights_bc = spark.sparkContext.broadcast(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d90255",
   "metadata": {},
   "source": [
    "### Load the model\n",
    "\n",
    "* two helper functions to\n",
    " * load the model\n",
    " * preporcess the bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    # load the model from brodcasted variables and return it\n",
    "    model = keras.models.model_from_json(model_json_bc.value)\n",
    "    model.set_weights(weights_bc.value)\n",
    "    return model\n",
    "\n",
    "\n",
    "def preprocess(bytes):\n",
    "    # * create image from bytes and resize\n",
    "    # * converts the image to numpy array\n",
    "    # * return the numpy array\n",
    "    img = Image.open(io.BytesIO(bytes)).resize((IMG_SIZE, IMG_SIZE))\n",
    "    arr_rescaled = img_to_array(img) / 255.0\n",
    "    return arr_rescaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b6e69c",
   "metadata": {},
   "source": [
    "### Implement the UDF\n",
    "\n",
    "* first we will try the vanilla UDF\n",
    "* it will take as input the bytes and return a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c953d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n",
    "\n",
    "@udf('float')\n",
    "def classify_udf(img_bytes):\n",
    "    # load the model\n",
    "    # preprocess the bytes\n",
    "    # reshape the array\n",
    "    # apply the model\n",
    "    # extract and return the prediction\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e79efea",
   "metadata": {},
   "source": [
    "### Call the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4922c1ab",
   "metadata": {},
   "source": [
    "### Implement Pandas UDF\n",
    "\n",
    "* now we will try the Pandas UDF\n",
    "* it will take as input pd.Series and return another pd.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27a78a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "@pandas_udf('float')\n",
    "def classify_udf_pd(img_bytes: pd.Series) -> pd.Series:\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc34047",
   "metadata": {},
   "source": [
    "### Call the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c193e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6576d2df",
   "metadata": {},
   "source": [
    "### Implement Pandas iter UDF\n",
    "\n",
    "* finally we will implement the Pandas iter UDF\n",
    "* it will take as input iterator of pd.Series and return iterator of pd.Series\n",
    "* for this purpose implement another helper function that will be called in the for-loop inside the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e0110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "def process_batch(model, batch):\n",
    "    # preprocess the bytes:\n",
    "    data = batch.map(preprocess)\n",
    "\n",
    "    # reshape the data:\n",
    "    input = np.stack(data)\n",
    "\n",
    "    # apply the model:\n",
    "    predictions = model.predict(input, batch_size=32)\n",
    "\n",
    "    # convert the predictions to pandas series\n",
    "    final_series = pd.Series(predictions[:, 0])\n",
    "\n",
    "    return final_series\n",
    "\n",
    "\n",
    "@pandas_udf('float')\n",
    "def classify_udf_pd_iter(img_bytes: Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
    "    # The Pandas UDF should be of the type PandasUDFType.SCALAR_ITER\n",
    "    # which should be specified using the type hints.\n",
    "\n",
    "    # load the model\n",
    "    \n",
    "    \n",
    "    # iterate over the img_bytes\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f113bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Call the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e01d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
