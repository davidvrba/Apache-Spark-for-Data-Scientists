{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c60a1fc",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "Similarly as in the notebook UDF-II, we will compute the entropy for each user. This time we want to add the result as a new column to the DataFrame. Similarly as if we call a window function instead of group by, we don't want to reduce the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd86aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, udf, lit, count, year, pandas_udf, avg, collect_list, size, array_distinct, desc, asc_nulls_last)\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf2b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('UDFs II')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a060d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "\n",
    "project_path = ('/').join(base_path.split('/')[0:-3]) \n",
    "\n",
    "answers_input_path = os.path.join(project_path, 'data/answers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db36470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will work with answers dataset:\n",
    "\n",
    "answersDF = (\n",
    "    spark\n",
    "    .read\n",
    "    .option('path', answers_input_path)\n",
    "    .load().drop('year')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3898390",
   "metadata": {},
   "source": [
    "## Hint\n",
    "\n",
    "* define a function that will take on the input a pandas dataframe and will return a pandas dataframe\n",
    " * this function should compute the entropy from one column and store the result in another column\n",
    " * see [docs](http://scipy.github.io/devdocs/reference/generated/scipy.stats.entropy.html#scipy.stats.entropy) for entropy\n",
    " * create a pandas dataframe using df.toPandas() and test if the function works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c289754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554c43d9",
   "metadata": {},
   "source": [
    "## Hint\n",
    "\n",
    "* now we want to use this function with the `applyInPandas`\n",
    " * see the [docs](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.GroupedData.applyInPandas.html#pyspark.sql.GroupedData.applyInPandas)\n",
    "* you need to define the schema of the final DataFrame\n",
    " * you can either do it manually\n",
    " * or you can copy `copy.deepcopy(some_schema)` the schema of the answersDF and [add](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.types.StructType.html#pyspark.sql.types.StructType.add) a new field to it\n",
    "* after having the schema, just group by `user_id` and call `applyInPandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc16db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# either define the schema manually:\n",
    "new_sch = StructType(\n",
    "    [\n",
    "        StructField('question_id', LongType(), True), \n",
    "        StructField('answer_id', LongType(), True), \n",
    "        StructField('creation_date', TimestampType(), True), \n",
    "        StructField('body', StringType(), True), \n",
    "        StructField('comments', LongType(), True), \n",
    "        StructField('user_id', LongType(), True), \n",
    "        StructField('score', LongType(), True),\n",
    "        StructField('result', FloatType(), True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# or copy the schema and add the new col:\n",
    "new_sch = copy.deepcopy(answersDF.schema).add('result', FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbdff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
